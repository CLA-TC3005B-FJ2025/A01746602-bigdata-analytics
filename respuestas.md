1. ¿Cómo te ayuda PySpark a manejar grandes volúmenes de datos?
Debido a la forma en la que esta herramienta opera, PySpark permite la división y el análisis de los datos en paralelo, lo cual ayuda a distribuir la carga de trabajo entre múltiples núcleos o nodos del sistema. Esto permite que el análisis de grandes volúmenes de datos sea mucho más rápido y eficiente.

2. ¿Qué ventajas encontraste al usar PySpark para realizar análisis de datos en comparación con otras herramientas que conoces?
        PySpark permite el procesamiento distribuido y en paralelo de datos, mientras que pandas solo opera en una sola máquina y un solo hilo.
        PySpark es más escalable: puede ejecutarse en distintos entornos. Pandas, por su parte, está limitado a entornos locales y no distribuidos.

3. ¿Qué otras operaciones de análisis podrías realizar con el nuevo conjunto de datos?
        Estadística avanzada (moda, desviación estándar, distribución)
        Análisis condicional (comparación de promedios, identificación de datos)
        Convertir los datos en indicadores para análisis posteriores
        Visualización de los resultados 